{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "c72a629dba5ae9edebcad565c17c3988d814021371aabb3db62cb04d2b10dbfe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Dataset\n",
    "\n",
    "# Import to grab popular ML datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Grab MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets grabbed by sklearn often have a similar dictionary strucutre containing\n",
    "# 1. DESCR key describing the dataset\n",
    "# 2. data key containing an array with one row per instance and one column per feature\n",
    "# 3. target key containing an array with the labels\n",
    "\n",
    "# Display arrays\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# 70,000 images with 784 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot out image (28 x 28) into an array with matplotlib\n",
    "some_digit = X[0]\n",
    "some_digital_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digital_image, cmap=mpl.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis('off')\n",
    "plt.show\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast y string variables into int variables\n",
    "import numpy as np\n",
    "y = y.astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test/train sets\n",
    "# Note: All sets are already shuffled\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary classifier for 5\n",
    "y_train_5 = (y_train == 5) # True for 5, false for non-5\n",
    "y_test_5 = (y_test == 5)\n",
    "\n",
    "# Training classifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGDCLassifier model\n",
    "# Note: very good at online learning\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "# Fit model\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict first image in array representing 5\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "# Correctly predicts the number 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate performance of SGDClassifier model at current time\n",
    "# It is more difficult to predict accuracy of classifier models than regressor models\n",
    "# Many different evaluation measures will be shown\n",
    "\n",
    "# Measuring accuracy using cross-validation\n",
    "# Similarly used in Chp_2 project\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "# In order to gain more control in this cross-validation process the following code implements\n",
    "# cross-validation manually\n",
    "\n",
    "# Random_state ensures repeatable outputs. 42 is generally used\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "# StratifiedKFold performs stratified sampling (expl. chp. 2)\n",
    "# at each iteration the code creates a clone of the classifier, trains the clone on the training folds, and makes predictions on the\n",
    "# test fold\n",
    "# then it counts the number of correct predictions and outputs the ratio of correct predictions\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    X_train_folds = X_train[train_index]\n",
    "    y_train_folds = y_train_5[train_index]\n",
    "    X_test_fold = X_train[test_index]\n",
    "    y_test_fold = y_train_5[test_index]\n",
    "\n",
    "    # Output ratio of correct predictions\n",
    "    clone_clf.fit(X_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(X_test_fold)\n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct / len(y_pred)) # 0.95035, 0.96035, 0.9604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_val_score to gauge accuracy (same as code above)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# See Chp 2 for further information\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "# 0.95035, 0.96035, 0.9604"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumb classifier that will look at every image in not-5 category\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self,X,y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1), dtype=bool)\n",
    "\n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "# returns 0.91125, 0.90855, 0.90915\n",
    "# About 10% of the images are 5. So if you guess that an image is 'not-5' you will be right about 90% of the time\n",
    "# Accuracy is not generally a good indicator for classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix -- more ideal method of calculating classifier performance\n",
    "# Essentially counts the number of times instances of class A are classified as class B\n",
    "# e.g knowing the amount of times the classifier confused images of 5s with 3s\n",
    "\n",
    "# Initial step -- calculate set of predictions\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "# cross_val_predict is similar to cross_val_score\n",
    "# performs k fold cross-validation but calculates predictions instead of scores\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix creation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_train_5, y_train_pred) # returns 53892, 687 (next row) 1891, 3530\n",
    "# each row represents an actual class, while each column represents a predicted class\n",
    "# Row 1: Correctly guessed non-5's, then false positives (incorrectly guessed as 5)\n",
    "# Row 2: False negatives (wrongly classified as non5s), then true positives (correctly classified as 5)\n",
    "# A perfect model would only have true negatives and true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_perfect_predictions = y_train_5 # pretending that the model has reached perfection\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions) # Confusion matrix based on a 'perfect model' with our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Precision calculations\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "print(precision_score(y_train_5, y_train_pred)) # Precision score, usually used in conjunction with recall score\n",
    "print(recall_score(y_train_5, y_train_pred)) # recall score\n",
    "\n",
    "# Precision score:  TP / (TP + FP)\n",
    "# Recall score: TP / (TP + FN)\n",
    "\n",
    "# Prints 0.83708 ...\n",
    "# Prints 0.651171 ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The F1 score is the harmonic mean between the precision score and recall score\n",
    "\n",
    "# F1 score:\n",
    "# 2/(1/precision + 1/recall)\n",
    "# Code for F1 Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The decision threshhold for the classifier cannot be changed directly\n",
    "# However, the decision scores that it uses to make predictions can be accessed\n",
    "\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "print(y_scores) # Print 2164.2203 ...\n",
    "\n",
    "threshhold = 0\n",
    "y_some_digit_pred = (y_scores > threshhold)\n",
    "print(y_some_digit_pred) # Print array [ True]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshhold = 8000 \n",
    "y_some_digit_pred = (y_scores > threshhold) # Boolean value for testing threshold vs score\n",
    "# when score is higher than threshhold it is true\n",
    "print(y_some_digit_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the right decision score to use across all instances\n",
    "# not just [0]\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\") # return decision scores\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precisions, recalls, threshholds = precision_recall_curve(y_train_5, y_scores) # Compue precision and recall for all possible threshholds\n",
    "\n",
    "# Function for plotting precision and recall\n",
    "# Graph can be used for precision / recall tradeoff calculations\n",
    "def plot_precision_recall_vs_threshhold(precisions,recalls,threshholds):\n",
    "    plt.plot(threshholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
    "    plt.plot(threshholds,recalls[:-1], \"g-\", label=\"Recall\")\n",
    "\n",
    "plot_precision_recall_vs_threshhold(precisions,recalls,threshholds) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# With a goal of 90% precision, the exact threshhold value can be calculated\n",
    "threshhold_90_precision = threshholds[np.argmax(precisions >= 0.90)]\n",
    "print(threshhold_90_precision) # prints 3370.019\n",
    "\n",
    "# Make predictions on the training set\n",
    "y_train_pred_90 = (y_scores >= threshhold_90_precision) # create boolean\n",
    "\n",
    "print(precision_score(y_train_5, y_train_pred_90)) # precision using boolean -- print 0.9000345\n",
    "print(recall_score(y_train_5, y_train_pred_90)) # recall using boolean -- print 0.479985"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve from sklearn.metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, threshholds = roc_curve(y_train_5, y_scores)\n",
    "\n",
    "def plot_roc_curve(fpr,tpr,label=None):\n",
    "    plt.plot(fpr,tpr,linewidth=2,label=label)\n",
    "    plt.plot([0,1],[0,1],'k--') # dashed diagonal\n",
    "\n",
    "plot_roc_curve(fpr,tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# AUC (area under the curve)\n",
    "# perfect classifier has AUC == 1 && ROC == 1\n",
    "# completely random classifier has AUC == 0.5 && ROC == 0.5\n",
    "roc_auc_score(y_train_5, y_scores) # print 0.960493 ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training RandomForestClassifier to compare ROC and ROC/AUC to SGDClassifier ROC ROC/AUC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42) # Create model\n",
    "y_probas_forest = cross_val_predict(forest_clf,X_train,y_train_5,cv=3,method=\"predict_proba\") # Gather probabilities\n",
    "\n",
    "y_scores_forest = y_probas_forest[:,1] # Gather scores\n",
    "fpr_forest,tpr_forest,threshholds_forest = roc_curve(y_train_5,y_scores_forest) # Info for plotting ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SGD to Random Forest\n",
    "plt.plot(fpr,tpr,\"b:\",label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest,tpr_forest,\"Random Forest\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_train_5,y_scores_forest) # print 0.998343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3) # prediction variable\n",
    "print(precision_score(y_train_5, y_train_pred_forest)) # prints 0.990508\n",
    "print(recall_score(y_train_5, y_train_pred_forest)) # prints 0.86626"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multiclass classifiers -- e.g comparing more than two classes. (as opposed to binary classifiers that compare 2 options)\n",
    "# multiclass operations can be conducted by using multiple binary class classifiers (one versus all strategy OvA / or one verses one OvO)\n",
    "'''\n",
    "Scikit-Learn detects when you try to use a binary classification algorithm for a multiâ€\n",
    "class classification task, and it automatically runs OvA (except for SVM classifiers for\n",
    "which it uses OvO).\n",
    "'''\n",
    "\n",
    "# Testing scikit-learn's detection operation -- trains SGDClassifier on the training set using the\n",
    "# the original target classes from 0 to 9 (y_train), instead of 5 v all target classes (y_train_5)\n",
    "sgd_clf.fit(X_train,y_train)\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "# decision_function method -- returns 10 scores per instance instead of just one per instance (trained 10 classifiers)\n",
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "print(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Highest score on some_digit_scores corresponds to 5\n",
    "print(np.argmax(some_digit_scores)) # returns highest prediction for some_digit_scores e.g [some_digit]\n",
    "\n",
    "print(sgd_clf.classes_) # all classes\n",
    "\n",
    "print(sgd_clf.classes_[5]) # fifth class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To change strategies using scikit-learn (OvA or OvO) you can use the OneVsOneClassifier or OneVsRestCLassifier classes\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42)) # Create model using OvO/SGDClassifier\n",
    "ovo_clf.fit(X_train,y_train) # Fit model\n",
    "print(ovo_clf.predict([some_digit])) # predict [some_digit]\n",
    "print(len(ovo_clf.estimators_)) # Print out length of all estimators (in this case 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier model using OvO\n",
    "forest_clf.fit(X_train,y_train)\n",
    "forest_clf.predict([some_digit])\n",
    "\n",
    "'''\n",
    "This time Scikit-Learn did not have to run OvA or OvO because Random Forest\n",
    "classifiers can directly classify instances into multiple classes. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Call predict_proba() to get a list of probabilities that the classifer assigned to each instance for each class (random forest)\n",
    "print(forest_clf.predict_proba([some_digit])) # 90% confidence the image is a 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the new classifiers\n",
    "\n",
    "print(cross_val_score(sgd_clf,X_train,y_train,cv=3,scoring=\"accuracy\")) # [0.87365 0.85835 0.8689 ]\n",
    "\n",
    "# Increased performance can be recieved by scaling inputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# scaling inputs\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler() # Create scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64)) # Fit scaler\n",
    "print(cross_val_score(sgd_clf,X_train_scaled,y_train,cv=3,scoring=\"accuracy\")) # Print score -- [0.8983 0.891  0.9018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Error Analysis\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3) # \n",
    "conf_mx = confusion_matrix(y_train, y_train_pred) # confusion matrix: p. 92-94\n",
    "print(conf_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot conf_mx\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "# The 5 square is a bit darker than the rest of the diagonal squares, which either means their are less in the dataset or\n",
    "# the classifier is less accurate on fives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# focus plot on errors\n",
    "# divide each value in the confusion matrix by the number of images in the corresponding class, to compare error rates\n",
    "\n",
    "row_sums = conf_mx.sum(axis=1,keepdims=True) \n",
    "norm_conf_mx = conf_mx / row_sums # calc rate\n",
    "\n",
    "np.fill_diagonal(norm_conf_mx,0) # p. 106\n",
    "plt.matshow(norm_conf_mx,cmap=plt.cm.gray)\n",
    "plt.show() # confusion matrix shows falsely classified images are mostly falsely classified as 8's when they are not\n",
    "# information shown on page 106 & in hands_on_ml_notes.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digits(instances, images_per_row=10, **options):\n",
    "    size = 28\n",
    "    images_per_row = min(len(instances), images_per_row)\n",
    "    images = [instance.reshape(size,size) for instance in instances]\n",
    "    n_rows = (len(instances) - 1) // images_per_row + 1\n",
    "    row_images = []\n",
    "    n_empty = n_rows * images_per_row - len(instances)\n",
    "    images.append(np.zeros((size, size * n_empty)))\n",
    "    for row in range(n_rows):\n",
    "        rimages = images[row * images_per_row : (row + 1) * images_per_row]\n",
    "        row_images.append(np.concatenate(rimages, axis=1))\n",
    "    image = np.concatenate(row_images, axis=0)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary, **options)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of 3's and 5's\n",
    "cl_a,cl_b = 3,5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)]\n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-label classification\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier # KNeighborsClassifier == multi-label capabilities\n",
    "\n",
    "y_train_large = (y_train >= 7) # is selected digit >= 7\n",
    "y_train_odd = (y_train % 2 == 1) # is selected digit odd\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd] # np array containing two target labels for each selected digit\n",
    "\n",
    "knn_clf = KNeighborsClassifier() # Create model\n",
    "knn_clf.fit(X_train, y_multilabel) # Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.predict([some_digit]) # Predict using KNeighborsClassifier\n",
    "# returns y_multilabel np array containing multi-label predictions for selected digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf,X_train,y_multilabel,cv=3) # Predict using cross_val_predict\n",
    "f1_score(y_multilabel,y_train_knn_pred,average=\"macro\") # compute average f1 score\n",
    "# to set weights use average=\"weighted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 231.84 \r\nL 231.84 231.84 \r\nL 231.84 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#p269b20a46f)\">\r\n    <image height=\"218\" id=\"image77d38effb5\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAABRFJREFUeJzt3bFL1H8cx/FTHBrUJYMI24T+AsdcGoo2J6HNJaKppEloimh0d/MfEayhIXIPdHDROGyIDI3A+80N9/7yu+/5Or17PNY337vvXT77wPfL575TvV6v1wGu1PSoTwAmgdAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0CZkZ9AtfVzs5OOV9fXy/n3W6372xhYWGgc+LmsqJBgNAgQGgQIDQIEBoECA0ChAYBU71erzfqk7iOvn//Xs7v3btXzquv1Vc+eaxoECA0CBAaBAgNAoQGAUKDAKFBgPtoA/rw4UM539zc7Dv7+/dveezMjG2C48aKBgFCgwChQYDQIEBoECA0CBAaBLiPNqDj4+Nyvri4OPBrX15eDnws15MVDQKEBgFCgwChQYDQIEBoEODy/hXZ2trqO9vY2CiPffXqVTl/9+5dOZ+dnS3n5FnRIEBoECA0CBAaBAgNAoQGAUKDAL9rdkVev37dd/b79+/y2Ldv35bz5eXlcv7s2bNyTp4VDQKEBgFCgwChQYDQIEBoECA0CLAf7RqamppqdXy32y3nd+7cafX6/H9WNAgQGgQIDQKEBgFCgwChQYDQIGBi76Pt7++X80ePHpXznz9/DvN0/tH0T9L2Plub9/769Ws5Pzs7K+crKyt9Z02fq+33Mso/dSsaBAgNAoQGAUKDAKFBgNAgYGwv71eXkTudTufTp0+hMxm+UV7eb9Lm3Npevr+8vBz4va+aFQ0ChAYBQoMAoUGA0CBAaBAgNAgY28c2HRwclPO2WypOT0/L+e3bt8t55c+fP+X86dOn5Xx3d7ecV5/927dv5bFNfvz4MfCx5+fn5fzBgwcDv/aoWdEgQGgQIDQIEBoECA0ChAYBQoOAsd2P1nbP1vPnz8v56upqOX/y5Emr968cHh6W86WlpYFf++PHj+X84cOHA7/2JLOiQYDQIEBoECA0CBAaBAgNAoQGARN7H63tfrTr/LVtb2+X8xcvXvSdNX2uk5OTcn737t1yPqmsaBAgNAgQGgQIDQKEBgFCgwChQcDY/q5j22dtPX78uJxPT9f/R43yWV1Ne+l+/frVd/bmzZvy2LW1tXK+t7dXzieVFQ0ChAYBQoMAoUGA0CBAaBAwtttk2mq7zaYyykv/nU59eX9+fr48tulzd7vdcr6wsFDOx5UVDQKEBgFCgwChQYDQIEBoECA0CBjbbTJtXVxclPNbt26V88+fPw/zdIZqbm6u7+zLly/lscvLy+X8/fv35Xxra6ucjysrGgQIDQKEBgFCgwChQYDQIEBoEGA/Gv9o2ivX9Eioly9fXtl732RWNAgQGgQIDQKEBgFCgwChQYDQIMB9NIaq6XFWlaOjo3J+//79gV971KxoECA0CBAaBAgNAoQGAUKDAKFBgPtoDFXTnrKZmf4/Jdr0p3iT/1StaBAgNAgQGgQIDQKEBgFCgwCPbWKomrbJVI+Fqh4nddNZ0SBAaBAgNAgQGgQIDQKEBgFCgwDbZCDAigYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CPgPI7732QV2L3IAAAAASUVORK5CYII=\" y=\"-6.64\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p269b20a46f\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# multi-output multiclass classification (or multioutput classification)\n",
    "\n",
    "# *************************************\n",
    "# Create model that takes noise out of digital images :\n",
    "\n",
    "# create training/test sets using MNIST images\n",
    "noise = np.random.randint(0,100,(len(X_train),784)) # Create pixel noise\n",
    "X_train_mod = X_train + noise # New X_train with added noise\n",
    "noise = np.random.randint(0, 100, (len(X_test), 784)) # Create pixel noise\n",
    "X_test_mod = X_test + noise # New X_test with pixel noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = X_test\n",
    "some_index = 5500\n",
    "\n",
    "knn_clf.fit(X_train_mod, y_train_mod) # fit model\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]]) # predict test mod 5500\n",
    "plot_digits(clean_digit) # plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"231.84pt\" version=\"1.1\" viewBox=\"0 0 231.84 231.84\" width=\"231.84pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 231.84 \r\nL 231.84 231.84 \r\nL 231.84 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g clip-path=\"url(#p69cdacffa5)\">\r\n    <image height=\"218\" id=\"image29276ba30f\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"7.2\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAABRFJREFUeJzt3bFL1H8cx/FTHBrUJYMI24T+AsdcGoo2J6HNJaKppEloimh0d/MfEayhIXIPdHDROGyIDI3A+80N9/7yu+/5Or17PNY337vvXT77wPfL575TvV6v1wGu1PSoTwAmgdAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0CZkZ9AtfVzs5OOV9fXy/n3W6372xhYWGgc+LmsqJBgNAgQGgQIDQIEBoECA0ChAYBU71erzfqk7iOvn//Xs7v3btXzquv1Vc+eaxoECA0CBAaBAgNAoQGAUKDAKFBgPtoA/rw4UM539zc7Dv7+/dveezMjG2C48aKBgFCgwChQYDQIEBoECA0CBAaBLiPNqDj4+Nyvri4OPBrX15eDnws15MVDQKEBgFCgwChQYDQIEBoEODy/hXZ2trqO9vY2CiPffXqVTl/9+5dOZ+dnS3n5FnRIEBoECA0CBAaBAgNAoQGAUKDAL9rdkVev37dd/b79+/y2Ldv35bz5eXlcv7s2bNyTp4VDQKEBgFCgwChQYDQIEBoECA0CLAf7RqamppqdXy32y3nd+7cafX6/H9WNAgQGgQIDQKEBgFCgwChQYDQIGBi76Pt7++X80ePHpXznz9/DvN0/tH0T9L2Plub9/769Ws5Pzs7K+crKyt9Z02fq+33Mso/dSsaBAgNAoQGAUKDAKFBgNAgYGwv71eXkTudTufTp0+hMxm+UV7eb9Lm3Npevr+8vBz4va+aFQ0ChAYBQoMAoUGA0CBAaBAgNAgY28c2HRwclPO2WypOT0/L+e3bt8t55c+fP+X86dOn5Xx3d7ecV5/927dv5bFNfvz4MfCx5+fn5fzBgwcDv/aoWdEgQGgQIDQIEBoECA0ChAYBQoOAsd2P1nbP1vPnz8v56upqOX/y5Emr968cHh6W86WlpYFf++PHj+X84cOHA7/2JLOiQYDQIEBoECA0CBAaBAgNAoQGARN7H63tfrTr/LVtb2+X8xcvXvSdNX2uk5OTcn737t1yPqmsaBAgNAgQGgQIDQKEBgFCgwChQcDY/q5j22dtPX78uJxPT9f/R43yWV1Ne+l+/frVd/bmzZvy2LW1tXK+t7dXzieVFQ0ChAYBQoMAoUGA0CBAaBAwtttk2mq7zaYyykv/nU59eX9+fr48tulzd7vdcr6wsFDOx5UVDQKEBgFCgwChQYDQIEBoECA0CBjbbTJtXVxclPNbt26V88+fPw/zdIZqbm6u7+zLly/lscvLy+X8/fv35Xxra6ucjysrGgQIDQKEBgFCgwChQYDQIEBoEGA/Gv9o2ivX9Eioly9fXtl732RWNAgQGgQIDQKEBgFCgwChQYDQIMB9NIaq6XFWlaOjo3J+//79gV971KxoECA0CBAaBAgNAoQGAUKDAKFBgPtoDFXTnrKZmf4/Jdr0p3iT/1StaBAgNAgQGgQIDQKEBgFCgwCPbWKomrbJVI+Fqh4nddNZ0SBAaBAgNAgQGgQIDQKEBgFCgwDbZCDAigYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CPgPI7732QV2L3IAAAAASUVORK5CYII=\" y=\"-6.64\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"p69cdacffa5\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"7.2\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "knn_clf.fit(X_train_mod, y_train_mod) # fit model\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]]) # Predict test mod 5500\n",
    "plot_digits(clean_digit) # plot\n",
    "\n",
    "# ********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}